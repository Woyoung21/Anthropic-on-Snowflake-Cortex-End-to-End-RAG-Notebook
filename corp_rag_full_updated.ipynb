{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68473617",
   "metadata": {},
   "source": [
    "# ❄️ Anthropic on Snowflake Cortex – End‑to‑End RAG Notebook\n",
    "This single notebook:\n",
    "1. Sets up a Snowflake RAG environment\n",
    "2. Ingests PDF & CSV docs\n",
    "3. Builds a Cortex Search Service\n",
    "4. Loads a Standards Library from Excel\n",
    "5. Classifies each control as **Yes / No / Needs Review**\n",
    "6. (Optional) Deploys a Streamlit dashboard for human QA\n",
    "\n",
    "Cells tagged **SQL** use the notebook's SQL runner; others run in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17cf8c",
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "\n",
    "-- SECTION 0 – Prerequisites  (SQL)\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "CREATE DATABASE IF NOT EXISTS corp_rag;\n",
    "CREATE SCHEMA   IF NOT EXISTS corp_rag;\n",
    "USE DATABASE corp_rag;\n",
    "USE SCHEMA   corp_rag;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9590cb",
   "metadata": {},
   "source": [
    "## 1  Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a93cb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ensure the notebook packages via the *Packages* pane:\n",
    "#   snowflake-ml-python>=1.8, snowflake, streamlit\n",
    "import pandas as pd, json, uuid, streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.cortex import complete\n",
    "from snowflake.core import Root\n",
    "\n",
    "session       = get_active_session()\n",
    "root          = Root(session)\n",
    "warehouse     = session.get_current_warehouse()\n",
    "database_name = session.get_current_database()\n",
    "schema_name   = session.get_current_schema()\n",
    "service_name  = \"document_search_service\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9675015e",
   "metadata": {},
   "source": [
    "## 2  Stage & list source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdb1bc",
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "\n",
    "CREATE STAGE IF NOT EXISTS docs_stage DIRECTORY = (ENABLE = TRUE);\n",
    "-- Drag & drop PDFs/CSVs into corp_rag ▸ docs_stage ▸ Upload\n",
    "LIST @docs_stage;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375b865",
   "metadata": {},
   "source": [
    "## 3  Parse PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363e60c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "from snowflake.snowpark.types import StringType\n",
    "pdf_files = [r[\"name\"].split(\"/\")[1] for r in session.sql(\"LIST @docs_stage/*.pdf\").collect()]\n",
    "\n",
    "def parse_pdf(fname):\n",
    "    q = \"\"\"SELECT TO_VARCHAR(\n",
    "               SNOWFLAKE.CORTEX.PARSE_DOCUMENT(@docs_stage, ?, {'mode':'OCR'}):content\n",
    "             ) AS text;\"\"\"\n",
    "    return session.sql(q, params=[fname]).collect()[0][\"TEXT\"].replace(\"'\", \"\")\n",
    "\n",
    "pdf_df = pd.DataFrame({\"file_name\": pdf_files,\n",
    "                       \"text\": [parse_pdf(f) for f in pdf_files]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc2c4e",
   "metadata": {},
   "source": [
    "## 4  Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101ccb9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "session.sql(\"\"\"CREATE OR REPLACE FILE FORMAT csv_fmt\n",
    "                 TYPE = CSV FIELD_OPTIONALLY_ENCLOSED_BY='\"' SKIP_HEADER=1\"\"\").collect()\n",
    "csv_snow = (session.read.schema(\"variant\")\n",
    "                     .option(\"file_format\",\"csv_fmt\")\n",
    "                     .csv(\"@docs_stage/*.csv\"))\n",
    "csv_flat = csv_snow.select(col(\"$1\").cast(StringType()).alias(\"text\"),\n",
    "                           col(\"METADATA$FILENAME\").alias(\"file_name\"))\n",
    "csv_df = csv_flat.to_pandas()\n",
    "full_df = pd.concat([pdf_df, csv_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ab191",
   "metadata": {},
   "source": [
    "## 5  Persist docs_text_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b3db0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "(session.create_dataframe(full_df)\n",
    "        .select(col(\"file_name\"), col(\"text\"))\n",
    "        .write.mode(\"overwrite\")\n",
    "        .save_as_table(\"docs_text_table\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a891c",
   "metadata": {},
   "source": [
    "## 6  Create / refresh Cortex Search Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a92e5",
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE document_search_service\n",
    "  ON text\n",
    "  ATTRIBUTES file_name\n",
    "  WAREHOUSE = ${warehouse}\n",
    "  TARGET_LAG = '1 day'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "  AS (\n",
    "    SELECT text, file_name FROM docs_text_table\n",
    "  );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4394d7",
   "metadata": {},
   "source": [
    "## 7  Standards Library skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053ae6e",
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "\n",
    "CREATE OR REPLACE TABLE standards (\n",
    "  id        INT AUTOINCREMENT,\n",
    "  standard  STRING,\n",
    "  answer    STRING,\n",
    "  rationale STRING\n",
    ");\n",
    "-- Example seeds\n",
    "INSERT INTO standards (standard) VALUES\n",
    " ('Does the report include an ISO‑27001 certificate?'),\n",
    " ('Is PII encrypted at rest?'),\n",
    " ('Is SOC 2 Type II coverage current?');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bab6ed",
   "metadata": {},
   "source": [
    "## 8  Classify each standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff9e77",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "MODEL = \"claude-3-5-sonnet\"\n",
    "svc = (root.databases[database_name]\n",
    "           .schemas[schema_name]\n",
    "           .cortex_search_services[service_name])\n",
    "def classify_row(row):\n",
    "    req = row.STANDARD\n",
    "    ctx = svc.search(query=req, columns=[\"text\"], limit=6).to_pandas()[\"text\"].str.cat(sep=\"\\n\\n\")\n",
    "    prompt = f\"\"\"You are an auditor. Decide if <context> proves <requirement> is met. \n",
    "Return JSON {{\\\"answer\\\":\\\"Yes|No|Needs Review\\\",\\\"rationale\\\":\"one line\"}}.\n",
    "<requirement>{req}</requirement>\n",
    "<context>{ctx}</context>\"\"\"\n",
    "    j = json.loads(complete(MODEL, prompt, temperature=0))\n",
    "    return (row.ID, j[\"answer\"], j[\"rationale\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e189194",
   "metadata": {},
   "source": [
    "## 9  Streamlit review dashboard (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dfa65a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save as streamlit/review_app.py if desired\n",
    "review_code = \"\"\"import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "df = session.table('standards').filter(\"answer IS NULL OR answer='Needs Review'\").to_pandas()\n",
    "st.title('🕵️ Needs‑Review Dashboard')\n",
    "edited = st.data_editor(df, num_rows='dynamic',\n",
    "    column_config={'answer': st.column_config.Selectbox('answer', options=['Yes','No','Needs Review'])})\n",
    "if st.button('Save changes'):\n",
    "    session.write_pandas(edited, 'tmp_review', auto_create_table=True)\n",
    "    session.sql(\\\"\\\"\\\"MERGE INTO standards t USING tmp_review s ON s.ID=t.ID\n",
    "                 WHEN MATCHED THEN UPDATE SET answer=s.answer, rationale=s.rationale\\\"\\\"\\\").collect()\n",
    "    st.success('Changes saved')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960efb5",
   "metadata": {},
   "source": [
    "## 11  Load StandardsLibrary.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432563f",
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "\n",
    "CREATE STAGE IF NOT EXISTS standards_stage DIRECTORY = (ENABLE = TRUE);\n",
    "-- Upload StandardsLibrary.xlsx to standards_stage\n",
    "LIST @standards_stage;\n",
    "\n",
    "CREATE OR REPLACE FILE FORMAT excel_fmt TYPE = 'EXCEL';\n",
    "\n",
    "CREATE OR REPLACE TABLE standards_library_raw AS\n",
    "SELECT *\n",
    "FROM @standards_stage (FILE_FORMAT => excel_fmt);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c455eac",
   "metadata": {},
   "source": [
    "## 12  Normalize Yes / No / Needs Review columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47414e61",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "raw = session.table(\"standards_library_raw\").to_pandas()\n",
    "questions = raw[ raw[\"Type\"].str.lower() == \"question\" ]\n",
    "norm = (questions.rename(columns={\"ID\":\"id\",\"Name\":\"standard\"})\n",
    "        [[\"id\",\"standard\",\"Yes\",\"No\",\"Needs Review\"]])\n",
    "(session.create_dataframe(norm)\n",
    "        .write.mode(\"overwrite\")\n",
    "        .save_as_table(\"standards\"))\n",
    "print(f\"{len(norm)} standards loaded to table.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480373b4",
   "metadata": {},
   "source": [
    "## 13  Classify unanswered rows and set flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad5ba3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "target = session.table(\"standards\").filter(\"Yes IS NULL AND No IS NULL AND `Needs Review` IS NULL\").to_pandas()\n",
    "updates = pd.DataFrame([classify_row(r) for _, r in target.iterrows()],\n",
    "                       columns=[\"ID\",\"ANSWER\",\"RATIONALE\"])\n",
    "session.write_pandas(updates, \"tmp_updates\", auto_create_table=True)\n",
    "session.sql(\"\"\"MERGE INTO standards t USING tmp_updates s ON s.ID = t.ID\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  Yes           = IFF(s.answer='Yes','X',NULL),\n",
    "  No            = IFF(s.answer='No','X',NULL),\n",
    "  `Needs Review`= IFF(s.answer='Needs Review','X',NULL),\n",
    "  rationale     = s.rationale;\n",
    "\"\"\").collect()\n",
    "print(\"Classification complete.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
